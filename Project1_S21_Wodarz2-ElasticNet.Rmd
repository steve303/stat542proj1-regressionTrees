---
title: "Project 1: Predict the Housing Prices in Ames"
date: "Spring 2021"
output:
  html_notebook:
    theme: readable
    toc: TRUE
    toc_float: TRUE
---

## Ames Housing Data

### Data set

Download the dataset, `Ames_data.csv`, from the Resouces page on Piazza. The dataset has 2930 rows (i.e., houses) and 83 columns. 

* The first column is "PID", the Parcel identification number; 
* The last column is the response variable, `Sale_Price`;
* The remaining 81 columns are explanatory variables describing (almost) every aspect of residential homes.

### Test IDs
  
Download `project1_testIDs.dat` from the Resouces page on Piazza. This file contains 879 rows and 10 columns, which will be used to generate **10 sets** of training/test splits from `Ames_data.csv`. Each column contains the 879 row-numbers of a test data.  

Here is how you generate a split of training and test using the j-th column of `project1_testIDs.dat` in R. 

```{r}
data <- read.csv("Ames_data.csv")
testIDs <- read.table("project1_testIDs.dat")
j <- 4
train <- data[-testIDs[,j], ]
test <- data[testIDs[,j], ]
test.y <- test[, c(1, 83)]
test <- test[, -83]
write.csv(train,"train.csv",row.names=FALSE)
write.csv(test, "test.csv",row.names=FALSE)
write.csv(test.y,"test_y.csv",row.names=FALSE)
```
Save the training and test as csv files. In particular, the test data are saved as two seperate two files: one containing just the feature vectors and the other one containing the response column. 

For your remaining analysis, you need to read the training and test data from the csv files.

```{r}
train <- read.csv("train.csv")
test <- read.csv("test.csv")
```
  


```{r}
# Step 0: Load necessary libraries
###########################################
# Step 0: Load necessary libraries
#
# YOUR CODE
# 
library(glmnet)
library(caret)
set.seed(1093)


### Used for both, pre-processing agnostic
winsor.vars = c("Lot_Frontage", "Lot_Area", "Mas_Vnr_Area", "BsmtFin_SF_2", "Bsmt_Unf_SF", "Total_Bsmt_SF", "Second_Flr_SF", 'First_Flr_SF', "Gr_Liv_Area", "Garage_Area", "Wood_Deck_SF", "Open_Porch_SF", "Enclosed_Porch", "Three_season_porch", "Screen_Porch", "Misc_Val")
                
remove.var <- c('Street', 'Utilities', 'Condition_2', 'Roof_Matl', 'Heating', 'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude','Latitude')

na_replace = function(x){if(is.na(x)){return(0)} else{return(x)}}
is_multi_level_factor = function(x){if(is.factor(x) && length(levels(x))>2){return(TRUE)} else{return(FALSE)}}

quan.value = 0.95

###########################################
# Step 1: Preprocess training data
#         and fit two models
#
train <- read.csv("train.csv")
#
# YOUR CODE
# 


# Remove Vars
train = train[, !names(train) %in% remove.var]

# Character column to one hot encoding
train[sapply(train, is.character)] = lapply(train[sapply(train, is.character)], as.factor)
train_factors = train
dummy = dummyVars("~.", data = train[sapply(train, is.factor)])
train_one_hot_encodings = data.frame(predict(dummy, newdata=train[sapply(train, is.factor)]))
train = cbind(train, train_one_hot_encodings)
train = train[,!names(train) %in% names(train[sapply(train, is.factor)])]


# Replace NA
train[,which(names(train) == "Garage_Yr_Blt")] = sapply(train[,which(names(train) == "Garage_Yr_Blt")],na_replace)

# Winsorize
for(var in winsor.vars){
  tmp = train[, var]
  myquan = quantile(tmp, probs = quan.value, na.rm = TRUE)
  tmp[tmp > myquan] <- myquan
  train[, var] = tmp
}


# Convert to train matrix
X.train = as.matrix(train[, !names(train) %in% c('PID','Sale_Price')])
Y.train = as.matrix(train[, names(train) %in% c('Sale_Price')])


# Elastic Net
cv.out = cv.glmnet(X.train, log(Y.train), alpha = 0.2)
best.lam = cv.out$lambda.min



###########################################
# Step 2: Preprocess test data
#         and output predictions into two files
#
test <- read.csv("test.csv")
#
# YOUR CODE
# 

# Remove vars
test = test[, !names(test) %in% remove.var]

# Character column to one hot encoding
for(i in 1:ncol(test)){
  if(is.character(test[,i])){
    test[,i] = factor(test[,i], levels = levels(train_factors[,i]))
  }
}
test_one_hot_encodings = data.frame(predict(dummy, newdata=test[sapply(test, is.factor)]))
test = cbind(test, test_one_hot_encodings)
test = test[,!names(test) %in% names(test[sapply(test, is.factor)])]

# Replace NA 
test[,which(names(test) == "Garage_Yr_Blt")] = sapply(test[,which(names(test) == "Garage_Yr_Blt")],na_replace)
na_values_matrix = which(is.na(test), arr.ind=TRUE)
for(i in 1:nrow(na_values_matrix)){
  test[na_values_matrix[i,1],na_values_matrix[i,2]] = 0
}

# Winsorize
for(var in winsor.vars){
  tmp = test[, var]
  myquan = quantile(tmp, probs = quan.value, na.rm = TRUE)
  tmp[tmp > myquan] <- myquan
  test[, var] = tmp
}

# Convert to test matrix
X.test = as.matrix(test[,!names(test) %in% c('PID')])

# Predict
test.y.pred = exp(predict(cv.out, s = best.lam, newx=X.test))
test.y.pred = data.frame(PID = test[,1], Sale_Price = test.y.pred[,1])
write.csv(test.y.pred, file = "mysubmission1.txt",  quote= FALSE, row.names = FALSE)

```


Performance
```{r}
pred <- read.csv("mysubmission1.txt")
names(test.y)[2] <- "True_Sale_Price"
pred <- merge(pred, test.y, by="PID")
sqrt(mean((log(pred$Sale_Price) - log(pred$True_Sale_Price))^2))
```


```{r}
winsor.vars = c("Lot_Frontage", "Lot_Area", "Mas_Vnr_Area", "BsmtFin_SF_2", "Bsmt_Unf_SF", "Total_Bsmt_SF", "Second_Flr_SF", 'First_Flr_SF', "Gr_Liv_Area", "Garage_Area", "Wood_Deck_SF", "Open_Porch_SF", "Enclosed_Porch", "Three_season_porch", "Screen_Porch", "Misc_Val")
                
remove.var <- c('Street', 'Utilities', 'Condition_2', 'Roof_Matl', 'Heating', 'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude','Latitude')

na_replace = function(x){if(is.na(x)){return(0)} else{return(x)}}
is_multi_level_factor = function(x){if(is.factor(x) && length(levels(x))>2){return(TRUE)} else{return(FALSE)}}

quan.value = 0.95

for(j in 1:10){
  set.seed(1093)
  train <- data[-testIDs[,j], ]
  test <- data[testIDs[,j], ]
  test.y <- test[, c(1, 83)]
  test <- test[, -83]
  write.csv(train,"train.csv",row.names=FALSE)
  write.csv(test, "test.csv",row.names=FALSE)
  write.csv(test.y,"test_y.csv",row.names=FALSE)
  train <- read.csv("train.csv")
  test <- read.csv("test.csv")
  # Remove Vars
  train = train[, !names(train) %in% remove.var]
  
  # Character column to one hot encoding
  train[sapply(train, is.character)] = lapply(train[sapply(train, is.character)], as.factor)
  train_factors = train
  dummy = dummyVars("~.", data = train[sapply(train, is.factor)])
  train_one_hot_encodings = data.frame(predict(dummy, newdata=train[sapply(train, is.factor)]))
  train = cbind(train, train_one_hot_encodings)
  train = train[,!names(train) %in% names(train[sapply(train, is.factor)])]
  
  
  # Replace NA
  train[,which(names(train) == "Garage_Yr_Blt")] = sapply(train[,which(names(train) == "Garage_Yr_Blt")],na_replace)
  
  # Winsorize
  for(var in winsor.vars){
    tmp = train[, var]
    myquan = quantile(tmp, probs = quan.value, na.rm = TRUE)
    tmp[tmp > myquan] <- myquan
    train[, var] = tmp
  }
  
  
  # Convert to train matrix
  X.train = as.matrix(train[, !names(train) %in% c('PID','Sale_Price')])
  Y.train = as.matrix(train[, names(train) %in% c('Sale_Price')])
  
  
  # Elastic Net
  cv.out = cv.glmnet(X.train, log(Y.train), alpha = 0.2)
  best.lam = cv.out$lambda.min
  
  
  
  ###########################################
  # Step 2: Preprocess test data
  #         and output predictions into two files
  #
  test <- read.csv("test.csv")
  #
  # YOUR CODE
  # 
  
  # Remove vars
  test = test[, !names(test) %in% remove.var]
  
  # Character column to one hot encoding
  for(i in 1:ncol(test)){
    if(is.character(test[,i])){
      test[,i] = factor(test[,i], levels = levels(train_factors[,i]))
    }
  }
  test_one_hot_encodings = data.frame(predict(dummy, newdata=test[sapply(test, is.factor)]))
  test = cbind(test, test_one_hot_encodings)
  test = test[,!names(test) %in% names(test[sapply(test, is.factor)])]
  
  # Replace NA 
  test[,which(names(test) == "Garage_Yr_Blt")] = sapply(test[,which(names(test) == "Garage_Yr_Blt")],na_replace)
  na_values_matrix = which(is.na(test), arr.ind=TRUE)
  for(i in 1:nrow(na_values_matrix)){
    test[na_values_matrix[i,1],na_values_matrix[i,2]] = 0
  }
  
  # Winsorize
  for(var in winsor.vars){
    tmp = test[, var]
    myquan = quantile(tmp, probs = quan.value, na.rm = TRUE)
    tmp[tmp > myquan] <- myquan
    test[, var] = tmp
  }
  
  # Convert to test matrix
  X.test = as.matrix(test[,!names(test) %in% c('PID')])
  
  # Predict
  test.y.pred = exp(predict(cv.out, s = best.lam, newx=X.test))
  test.y.pred = data.frame(PID = test[,1], Sale_Price = test.y.pred[,1])
  write.csv(test.y.pred, file = paste("mysubmission",j,".txt",sep=""),  quote= FALSE, row.names = FALSE)
}
```

```{r}
for(j in 1:10){
pred <- read.csv(paste("mysubmission",j,".txt", sep=""))
test <- data[testIDs[,j], ]
test.y <- test[, c(1, 83)]
names(test.y)[2] <- "True_Sale_Price"
pred <- merge(pred, test.y, by="PID")
print(sqrt(mean((log(pred$Sale_Price) - log(pred$True_Sale_Price))^2)))
}
```

